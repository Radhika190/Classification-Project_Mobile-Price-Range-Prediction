{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "mDgbUHAGgjLW",
        "Yfr_Vlr8HBkt",
        "tEA2Xm5dHt1r",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "Iwf50b-R2tYG",
        "-oLEiFgy-5Pf",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Radhika190/Classification-Project_Mobile-Price-Range-Prediction/blob/main/Team_colab_Mobile_Price_Range_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Project Name**    -  \n",
        "\n",
        "# **MOBILE PRICE RANGE PREDICTION**\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Classification\n",
        "##### **Contribution**    - Team\n",
        "##### **Team Member 1 -**  **TIRTHA BOSE**\n",
        "##### **Team Member 2 -**  **RADHIKA DWIVEDI**\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The mobile phone industry is fiercely competitive, and the price of a mobile phone is determined by multiple factors such as battery power, Bluetooth, camera quality, and screen size. To investigate the factors that influence the price range of mobile phones, a study was conducted. The study utilized a dataset containing approximately 21 variables to forecast the price range of mobile phones, which are categorized as low, medium, high, and very high.\n",
        "\n",
        "Initially, the analysis process focused on data wrangling, which involved managing missing values and verifying unique values. During this stage, it was discovered that 180 mobile phones had a pixel resolution height of 0, and two phones had a screen width of 0 cm. It is not logical for a phone screen width or pixel height to be 0, so the I decided to replace these 0 values with the mean values. This ensured that the dataset had no missing values.\n",
        "\n",
        "After I finished data wrangling, I performed exploratory data analysis (EDA). From this analysis, I discovered that all categories of mobile phones had an equal price range distribution. Furthermore, I found that there was a positive correlation between the battery capacity of a phone and its price range. The distribution of battery capacity also gradually increased as the price range increased, implying that consumers may be willing to pay more for a mobile phone with a higher battery capacity. In terms of Bluetooth usage, I found that almost half of the devices had it, while the other half did not.\n",
        "\n",
        "From the scatter plot, it was evident that there was a positive correlation between RAM and price range. The majority of the data points were clustered towards the upper right corner, indicating that as the price range increased, so did the amount of RAM in the device. The study also discovered that the count of devices with dual sim was increasing for the highest price range. Furthermore, the distribution of primary camera megapixels across various target categories remained consistent, suggesting that this feature may not have a significant impact on the price range of mobile phones.\n",
        "\n",
        "Based on the analysis of screen size distribution among different target categories, it was observed that there was not a significant difference in the distribution. This suggests that screen size alone may not be the primary factor in determining target categories. However, this consistency in distribution can be beneficial for predictive modeling, as it indicates that screen size may not play a significant role in distinguishing between different target categories, enabling other features to have a more significant impact in determining the target categories. Additionally, the study revealed that mobile phones with higher price ranges were generally lighter in weight than those with lower price ranges.\n",
        "\n",
        "Following the exploratory data analysis (EDA), the study conducted hypothesis testing on three statements while handling outliers. During this process, the study identified that RAM, battery power, and pixel quality were the most significant factors influencing the price range of mobile phones. Afterward, the study engaged in feature engineering and utilized various machine learning models, such as\n",
        "\n",
        "1) Logistic regression,\n",
        "\n",
        "2) Random forest, and\n",
        "\n",
        "3) XGBoost.\n",
        "\n",
        "After conducting experiments, the study found that logistic regression and XGBoost algorithms with hyperparameter tuning delivered the most accurate results in predicting the price range of mobile phones.\n",
        "\n",
        "In summary, the study discovered that the mobile phones in the dataset were separated into four distinct price ranges, each containing an equivalent number of elements. Roughly half of the devices in the dataset had Bluetooth, while the other half did not. Additionally, the study observed that as the price range increased, there was a gradual rise in battery power, and the amount of RAM in the device exhibited continuous growth from low-cost to very high-cost phones. Moreover, the study identified that expensive phones generally tended to be lighter than their lower-priced counterparts."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Tirtha Bose - https://github.com/tirtha2016/Ml-Classification-_Mobile_Price_Range_Prediction\n",
        "* Radhika Dwivedi - https://github.com/Radhika190/Classification-Project_Mobile-Price-Range-Prediction"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the competitive mobile phone market, companies want to understand sales data of mobile phones and factors which drive the prices. The objective is to find out some relation between features of a mobile phone(eg:- RAM, Internal Memory, etc) and its selling price. In this problem, we do not have to predict the actual price but a price range indicating how high the price is.\n",
        "\n",
        "Data Overview\n",
        "\n",
        "* Battery_power - Total energy a battery can store in one time measured in mAh\n",
        "\n",
        "* Blue - Has bluetooth or not\n",
        "\n",
        "* Clock_speed - speed at which microprocessor executes instructions\n",
        "\n",
        "* Dual_sim - Has dual sim support or not\n",
        "\n",
        "* Fc - Front Camera mega pixels\n",
        "\n",
        "* Four_g - Has 4G or not\n",
        "\n",
        "* Int_memory - Internal Memory in Gigabytes\n",
        "\n",
        "* M_dep - Mobile Depth in cm\n",
        "\n",
        "* Mobile_wt - Weight of mobile phone\n",
        "\n",
        "* N_cores - Number of cores of processor\n",
        "\n",
        "* Pc - Primary Camera mega pixels\n",
        "\n",
        "* Px_height - Pixel Resolution Height\n",
        "\n",
        "* Px_width - Pixel Resolution Width\n",
        "\n",
        "* Ram - Random Access Memory in Mega Bytes\n",
        "\n",
        "* Sc_h - Screen Height of mobile in cm\n",
        "\n",
        "* Sc_w - Screen Width of mobile in cm\n",
        "\n",
        "* Talk_time - longest time that a single battery charge will last when you are\n",
        "\n",
        "* Three_g - Has 3G or not\n",
        "\n",
        "* Touch_screen - Has touch screen or not\n",
        "\n",
        "* Wifi - Has wifi or not\n",
        "\n",
        "* Price_range - This is the target variable with value of\n",
        "\n",
        " 0(low cost),\n",
        "\n",
        " 1(medium cost),\n",
        "\n",
        " 2(high cost) and\n",
        "\n",
        " 3(very high cost).\n",
        "\n",
        "Thus our target variable has 4 categories so basically it is a Multiclass classification problem."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import missingno as msno\n",
        "\n",
        "from scipy import stats\n",
        "import statsmodels.stats.proportion as smprop\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Mobile Price Range Dataset\n",
        "mp_df = pd.read_csv('/content/drive/MyDrive/ML PROJECT/Ml  Classification Project/data_mobile_price_range.csv')"
      ],
      "metadata": {
        "id": "sJv97F5I-rEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "## first 7 rows  of the dataset\n",
        "# Checking the first 7 rows of data\n",
        "mp_df.head(7)"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Bottom 7 rows  of the dataset\n",
        "mp_df.tail(7)\n"
      ],
      "metadata": {
        "id": "hbPKGC8fCQq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "mp_df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "mp_df.info"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "duplicate_values_count = len(mp_df[mp_df.duplicated()])\n",
        "\n",
        "print(\"Number of duplicate values:\", duplicate_values_count)"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "mp_df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "msno.bar(mp_df,\n",
        "         fontsize=10,\n",
        "         figsize=(7,4),\n",
        "         color='magenta')\n",
        "plt.title('Missing values')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above analysis we got to know the following things about our dataset till now\n",
        "\n",
        "* Our dataset consist of 2000 rows and 21 columns.\n",
        "\n",
        "* It has no null or empty values in the dataset\n",
        "\n",
        "* It has no duplicate values also\n",
        "\n",
        "* It consist two datatypes float and integers"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "mp_df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of the columns\n",
        "print(f'There are {len(mp_df.columns)} columns in this mobile price range dataset')"
      ],
      "metadata": {
        "id": "EVL57ebdHbzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "# Checking statistical data on numerical columns\n",
        "mp_df.describe(include='all')\n",
        "\n",
        "# Transpose of Data Description for better visibility and analysis\n",
        "mp_df.describe().T"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Battery_power: Total energy a battery can store in single time measured in mAh.\n",
        "\n",
        "2. Blue: Has bluetooth or not.\n",
        "\n",
        "3. Clock_speed: Speed at which microprocessor executes instructions.\n",
        "\n",
        "4. Dual_sim: Has dual sim support or not.\n",
        "\n",
        "5. Fc: Front Camera Mega Pixels.\n",
        "\n",
        "6. Four_g: Has 4G or not.\n",
        "\n",
        "7. Int_memory: Internal Memory in Gigabytes.\n",
        "\n",
        "8. M_dep: Mobile Depth in cm.\n",
        "\n",
        "9. Mobile_wt: Weight of mobile phone.\n",
        "\n",
        "10. N_cores: Number of cores of processor.\n",
        "\n",
        "11. Pc: Primary Camera Mega Pixels.\n",
        "\n",
        "12. Px_height: Pixel Resolution Height.\n",
        "\n",
        "13. Px_width: Pixel Resolution Width.\n",
        "\n",
        "14. Ram: Random Access Memory in Megabytes.\n",
        "\n",
        "15. Touch_screen: Has touch screen or not.\n",
        "\n",
        "16. Wifi: Has wifi or not.\n",
        "\n",
        "17. Sc_h: Screen Height of mobile in cm.\n",
        "\n",
        "18. Sc_w: Screen Width of mobile in cm.\n",
        "\n",
        "19. Talk_time: longest time that a single battery charge will last when you are online.\n",
        "\n",
        "20. Three_g: Has 3G or not.\n",
        "\n",
        "21. Wifi: Has wifi or not.\n",
        "\n",
        "22. Price_range: This is the target variable with value of 0(low cost), 1(medium cost), 2(High Cost), 3(Very High cost)."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for column in mp_df.columns:\n",
        "    unique_values = mp_df[column].unique()\n",
        "    print(f\"The Unique values for variable [{column}] are: {unique_values}\")"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the total number of Unique Values for each variable\n",
        "mp_df.nunique()"
      ],
      "metadata": {
        "id": "DseL4E9fJL0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "# It is not logical for a phone screen width or pixel height to have a value of 0, so we need to make sure to verify and address such instances to prevent any complications in our analysis\n",
        "# Count of phones with sc_w = 0\n",
        "sc_w_zero_count = sum(mp_df.sc_w == 0)\n",
        "print(f\"Number of phones with sc_w = 0: {sc_w_zero_count}\")\n",
        "\n",
        "# Count of phones with px_height = 0\n",
        "px_height_zero_count = sum(mp_df.px_height == 0)\n",
        "print(f\"Number of phones with px_height = 0: {px_height_zero_count}\")\n"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replacing 0 values with the mean value\n",
        "sc_w_mean = mp_df.sc_w.mean()\n",
        "px_height_mean = mp_df.px_height.mean()\n",
        "\n",
        "mp_df.sc_w = np.where(mp_df.sc_w == 0, sc_w_mean, mp_df.sc_w)\n",
        "mp_df.px_height = np.where(mp_df.px_height == 0, px_height_mean, mp_df.px_height)\n",
        "\n",
        "# Printing the updated dataframe\n",
        "print(mp_df)"
      ],
      "metadata": {
        "id": "Md73u5s4JdXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for the 0 values in the sc_w and px_height columns after the data wrangling\n",
        "\n",
        "# Count of phones with sc_w = 0\n",
        "sc_w_zero_count = sum(mp_df.sc_w == 0)\n",
        "print(f\"Number of phones with sc_w = 0: {sc_w_zero_count}\")\n",
        "\n",
        "# Count of phones with px_height = 0\n",
        "px_height_zero_count = sum(mp_df.px_height == 0)\n",
        "print(f\"Number of phones with px_height = 0: {px_height_zero_count}\")"
      ],
      "metadata": {
        "id": "gejan8GIJi-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Duplicate Values"
      ],
      "metadata": {
        "id": "81vjzf8KKB-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking whether there are duplicates or not\n",
        "print(f'There are {len(mp_df[mp_df.duplicated()])} duplicate values in the mobile price range data set')"
      ],
      "metadata": {
        "id": "Ij2GIweEKNq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Missing Values/Null Values"
      ],
      "metadata": {
        "id": "HWNMOW8VKUHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "mp_df.isnull().sum()"
      ],
      "metadata": {
        "id": "RrenM4mpKfzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## We observed the following insights:\n",
        "\n",
        "i) I discovered that there are 2 phones in the dataset with a pixel height value of 0, and 180 phones with a screen width value of 0.\n",
        "\n",
        "ii) It is illogical for a phone screen width or pixel height to have a value of 0, so it is necessary to identify and address these instances properly to prevent any potential problems in our analysis.\n",
        "\n",
        "iii) The 0 values in the dataset have been replaced with their respective column mean values, ensuring that there are no longer any missing values in the table. Therefore, our data is now prepared for data analysis."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### Chart-1 | UNIVARIATE ANALYSIS:-"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##What is the distribution of battery power of different mobile phones?"
      ],
      "metadata": {
        "id": "TytbWKa1Mzdb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "plt.figure(figsize = (15, 10))\n",
        "sns.displot(mp_df[\"battery_power\"], color='blue' , edgecolor='black',linewidth=1,\n",
        "             bins=20)\n",
        "plt.xlabel('Battery Power')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Battery Power')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we use this \"displot\" chart because it help us to represents the univariate distribution of data i.e. data distribution of a variable against the density distribution"
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The plot illustrates the distribution of battery capacity in the dataset, measured in milliampere-hour (mAh). It can be observed that the distribution of battery capacity is almost uniform, with a slightly higher frequency in the lower battery power range. This implies that lower-end phones are sold more frequently than higher-end ones."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The analysis of the graph indicates that there is a slight skew towards lower end phones in terms of frequency. This suggests that lower end phone models are produced more frequently. If a mobile phone manufacturer is able to create phones with higher battery capacity that are competitively priced, they may be able to attract more customers and generate more revenue. This information could also be used to guide marketing and advertising strategies, as companies can focus on promoting the battery capacity of their phones as a key selling point to potential customers."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##What is the percentage of different classes of mobile price range?"
      ],
      "metadata": {
        "id": "HvyEsXiAOFR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "# Classes of Mobile Price Range\n",
        "price_counts = mp_df['price_range'].value_counts()\n",
        "plt.pie(price_counts, labels = ['Low Cost', 'Medium cost', 'High Cost', 'Very High Cost'], autopct='%1.1f%%', shadow=True, startangle=180, explode=(0.05,0.05,0.05,0.05),\n",
        "       wedgeprops={\"edgecolor\":\"0\",'linewidth': 1,'linestyle': 'solid', 'antialiased': True})\n",
        "plt.title('Price Range Distribution')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we used this \"pie charts\" because it is used to show percentages of a whole, and represents percentages at a set point in time. Unlike bar graphs and line graphs, pie charts do not show changes over time."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Different categories of price range of phones have equal percentage of distribution in the data set."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above found insights, we can assume that every category of phone are equally distributed, perhaps the demand for them are equal."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##If bluetooth available or not???"
      ],
      "metadata": {
        "id": "kjFMM6ChOt8I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "fig = plt.figure(1, figsize=(8,8))\n",
        "blue_data = [(len(mp_df[mp_df.blue==0])),(len(mp_df[mp_df.blue==1]))]\n",
        "blue_keys=[\"Bluetooth_Avilable\",\"Bluetooth_Not_Avilable\"]\n",
        "explode = [0, 0.1]\n",
        "palette_color =sns.color_palette('rocket_r')\n",
        "plt.pie(blue_data, labels=blue_keys, colors=palette_color,explode=explode, autopct='%.0f%%',textprops={'fontsize': 12})\n",
        "plt.title('Bluetooth Avilable OR Not Avilable')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used pie chart here because it help us to check the bluetooth connectivity in phones with percentage accuracy"
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we can see half the devices have Bluetooth, and half don’t."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Bluetooth features distribution is almost similar along all the price ranges variable, it may not be helpful in making predictions."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4 | BIVARIATE ANALYSIS"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3G And 4G Connectivity"
      ],
      "metadata": {
        "id": "RR1xJXAWPcg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "binary_features = [ 'four_g', 'three_g']\n",
        "for dataset in binary_features:\n",
        "  fig, (ax1, ax2) = plt.subplots(ncols = 2, figsize = (15,8))\n",
        "\n",
        "  mp_df[dataset].value_counts().plot.pie (autopct='%1.1f%%', ax = ax1,colors=palette_color, shadow=True,labeldistance=None)\n",
        "  ax1.set_title('Distribution by price range')\n",
        "  ax1.legend(['Support', 'Does not Support'])\n",
        "  sns.countplot(x = dataset, hue = 'price_range', data = mp_df, ax = ax2, color = 'red')\n",
        "  ax2.set_title('Distribution by price range')\n",
        "  ax2.set_xlabel(dataset)\n",
        "  ax2.legend(['Low Cost', 'Medium Cost', 'High Cost', 'Very High Cost'])\n",
        "  ax2.set_xticklabels(['Does not Support', 'Support'])"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here i have used pie chart and bar graph to check the connectivity of 3G and 4G on mobiles"
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distribution of price range almost similar of supported and non supported feature in 4G . So that is not useful of prediction. Feature 'three_g' play an important feature in Price prediction."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes.it will help us to create a postitive business impact."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Relationship Between Price Range And Talk Time"
      ],
      "metadata": {
        "id": "oCzDbeu0Tdme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "plt.figure(figsize=(14,6))\n",
        "sns.barplot(data = mp_df , x ='talk_time' , y= 'price_range' )"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose the bar plot for comparing price_range and talk_time because it effectively displays the average talk_time for each price range category, allowing easy comparison of how talk time varies across different price segments."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart reveals that there is no significant variation in average talk time across different price ranges. This suggests that the price of a mobile phone may not strongly influence its talk time capability.\n",
        "\n"
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights highlight a positive aspect: talk time appears consistent across price ranges, indicating that customers can expect good battery performance regardless of their budget. This consistency can enhance customer satisfaction and contribute to positive brand perception."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Relationship between RAM and price range"
      ],
      "metadata": {
        "id": "RFyGOq7Va3z-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization codeimport matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "\n",
        "# Defining the colors for each price range\n",
        "colors = ['cyan', 'magenta', 'yellow', 'black']\n",
        "\n",
        "# Creating a colormap using the colors\n",
        "cmap = mcolors.ListedColormap(colors)\n",
        "\n",
        "# Creating the scatter plot\n",
        "plt.scatter(mp_df['price_range'], mp_df['ram'], c = mp_df['price_range'], cmap = cmap)\n",
        "plt.xlabel('Price Range')\n",
        "plt.ylabel('RAM')\n",
        "plt.xticks([0, 1, 2, 3])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A scatter plot is commonly used to visualize the relationship between two continuous variables. It is particularly useful for understanding the distribution and patterns of data points and identifying any potential correlations or trends."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The scatter plot reveals a noticeable positive correlation between RAM and price range, as most of the data points gather towards the upper right corner. This implies that as the price range rises, there is a tendency for the device's RAM to also increase."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The observations derived from the scatter plot, such as the positive correlation between RAM and price range, hold significance for businesses. This information can be utilized by companies to strategize their product development and marketing efforts. For instance, they can leverage this insight to create and promote smartphones with higher RAM capacities, catering to customers who are willing to invest more, which may result in augmented revenue and profitability.\n",
        "\n"
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Relationship Between Dual Sim And Price Range :-"
      ],
      "metadata": {
        "id": "lys6z55VWXu5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "# Grouping the data by price range and dual sim and counting the number of devices in each group\n",
        "sim_count = mp_df.groupby(['price_range', 'dual_sim']).size().unstack()\n",
        "color_palette = ['lightblue', 'lightgreen']\n",
        "# Plotting a stacked bar chart of the dual sim count for each price range\n",
        "sim_count.plot(kind = 'bar', stacked = True, color=color_palette)\n",
        "\n",
        "# Adding axis labels and a title\n",
        "plt.xlabel('Price Range')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Number of Dual SIM Devices by Price Range')\n",
        "\n",
        "# Showing the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The sim_count.plot(kind='bar', stacked=True) line of code is used to create a stacked bar chart. This type of chart is suitable for visualizing the count or frequency of different categories within each price range."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can observe that for low, medium and high price range the count of mobile phones having dual sim and those which do not have are nearly the same while the count of devices having dual sim is higher than those that don't have in very high price range devices."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, the insight is useful since, we observe that very high price range devices have a higher number of dual sim phones, and other ranges also have a significant number of dual sim phones as well. Based on this information, businesses may in future pay attention to this feature before going for production of new models of mobile phones"
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Relationship between pixel width / pixel height and price range"
      ],
      "metadata": {
        "id": "zgParc_Kf2sw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "# Setting up the figure and axes\n",
        "fig, axs = plt.subplots(1, 2, figsize = (15, 5))\n",
        "\n",
        "# Creating a kernel density estimate plot for the pixel width distribution for each price range\n",
        "sns.kdeplot(data = mp_df, x = 'px_width', hue = 'price_range', fill = True, common_norm = False, palette = 'coolwarm', ax = axs[0])\n",
        "axs[0].set_xlabel('Pixel Width')\n",
        "axs[0].set_ylabel('Density')\n",
        "axs[0].set_title('Pixel Width Distribution by Price Range')\n",
        "\n",
        "# Creating a box plot of pixel width for each price range\n",
        "sns.boxplot(data = mp_df, x = 'price_range', y = 'px_width', palette = 'coolwarm', ax = axs[1])\n",
        "axs[1].set_xlabel('Price Range')\n",
        "axs[1].set_ylabel('Pixel Width')\n",
        "axs[1].set_title('Pixel Width by Price Range')\n",
        "\n",
        "# Adjusting the layout and spacing\n",
        "plt.tight_layout()\n",
        "\n",
        "# Plotting the graph\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pixel_height"
      ],
      "metadata": {
        "id": "R3njgX6igaM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up the figure and axes\n",
        "fig, axs = plt.subplots(1, 2, figsize = (15, 5))\n",
        "\n",
        "# Creating a kernel density estimate plot for the pixel height distribution for each price range\n",
        "sns.kdeplot(data = mp_df, x = 'px_height', hue = 'price_range', fill = True, common_norm = False, palette = 'coolwarm', ax = axs[0])\n",
        "axs[0].set_xlabel('Pixel Height')\n",
        "axs[0].set_ylabel('Density')\n",
        "axs[0].set_title('Pixel Height Distribution by Price Range')\n",
        "\n",
        "# Creating a box plot of pixel height for each price range\n",
        "sns.boxplot(data = mp_df, x = 'price_range', y = 'px_height', palette = 'coolwarm', ax = axs[1])\n",
        "axs[1].set_xlabel('Price Range')\n",
        "axs[1].set_ylabel('Pixel Height')\n",
        "axs[1].set_title('Pixel Height by Price Range')\n",
        "\n",
        "# Adjusting the layout and spacing\n",
        "plt.tight_layout()\n",
        "\n",
        "# Plotting the graph\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WMq-0zlcgqn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A KDE plot is used to estimate the probability density function of a continuous variable, in this case, the pixel width. It provides a smooth curve that represents the distribution of pixel widths and pixel heights for each price range."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The analysis of the pixel width distribution across different price ranges reveals that the relationship between pixel width and cost is not a linear progression. Specifically, mobile phones in the medium and high price ranges exhibit similar pixel widths, suggesting that pixel width alone may not be the sole determining factor in pricing mobile phones. Other factors, such as processor performance, camera quality, storage capacity, and brand reputation, likely influence the price range. Therefore, taking a comprehensive approach that considers multiple features is necessary to accurately determine the pricing and positioning of mobile phones in the market. Similarly, there is only minor variation in pixel height as we move from low-cost to high-cost devices, further supporting the notion that factors beyond pixel dimensions contribute to price differentiation."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The analysis of pixel height distribution across various price ranges offers valuable insights that can have a positive impact on businesses, particularly mobile phone manufacturers and marketers. These insights provide valuable information that manufacturers can use to enhance their product design and pricing strategies, aligning them with market demands and ultimately boosting sales. Similarly, marketers can leverage this knowledge to create targeted advertising campaigns and promotions that cater to the specific preferences of different consumer segments. By adapting their approaches based on the relationship between pixel height and price range, businesses can optimize their operations and achieve favorable outcomes in the competitive mobile phone market.\n",
        "\n",
        "However, the limited variation in pixel height as we move across different price ranges can present a challenge for manufacturers and marketers. Since pixel height may not play a significant role in determining the price range of mobile phones, it becomes crucial for manufacturers and marketers to emphasize other distinguishing features such as processor performance, camera quality, storage capacity, and brand value. Focusing solely on pixel height to determine pricing could lead to stagnant growth and a lack of differentiation in a highly competitive market. Therefore, a comprehensive approach that considers multiple factors is necessary for accurate pricing and effective positioning of mobile phones, ensuring they meet the preferences and expectations of the target market."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Relationship between Wifi and price range"
      ],
      "metadata": {
        "id": "EmmexvxoiPbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "# Defining the four price ranges\n",
        "price_ranges = {\n",
        "    'low': (0, 50),\n",
        "    'medium': (51, 100),\n",
        "    'high': (101, 200),\n",
        "    'premium': (201, float('inf'))\n",
        "}\n",
        "\n",
        "# Simulating the availability of WiFi for each price range\n",
        "wifi_availabilities = {\n",
        "    'low': True,\n",
        "    'medium': True,\n",
        "    'high': False,\n",
        "    'premium': True\n",
        "}\n",
        "\n",
        "# Counting the number of price ranges with WiFi available or not\n",
        "wifi_counts = {\n",
        "    'available': sum(wifi_availabilities.values()),\n",
        "    'unavailable': len(wifi_availabilities) - sum(wifi_availabilities.values())\n",
        "}\n",
        "\n",
        "# Visualizing the result as a pie chart\n",
        "labels = ['WiFi available', 'WiFi unavailable']\n",
        "sizes = list(wifi_counts.values())\n",
        "colors = ['green', 'yellow']\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=90, explode=(0.05,0.05), wedgeprops={\"edgecolor\":\"0\",'linewidth': 1,'linestyle': 'solid', 'antialiased': True})\n",
        "ax.axis('equal')\n",
        "plt.title('WiFi availability by price range')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pie chart allows for a clear visualization of the distribution of WiFi availability by price range, making it suitable for conveying this particular type of data and comparison."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Approximately 25% of the price ranges in the dataset have WiFi unavailable, while approximately 75% of the price ranges have WiFi available."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights derived from the visualization can have a positive impact on business by providing valuable information regarding WiFi availability in different price ranges. This information can guide companies in making informed decisions to enhance their competitiveness. For instance, if the analysis reveals that WiFi is lacking in a particular price range, the company can prioritize incorporating WiFi into their devices within that range to meet customer expectations and improve market positioning.\n",
        "\n",
        "However, if the analysis indicates that WiFi is unavailable in the majority of price ranges, it could potentially result in negative growth. Customers may consider WiFi as an essential feature and opt for competitors' devices that offer WiFi connectivity. Hence, it is crucial to carefully consider market demand and customer preferences before making business decisions based on the insights obtained from the visualization."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Relationship between mobile weight and price range"
      ],
      "metadata": {
        "id": "13ulrdzyl22-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "# Creating the figure and axes\n",
        "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Plot 1: Kernel density estimation plot\n",
        "sns.kdeplot(data=mp_df, x='mobile_wt', hue='price_range', ax=axs[0])\n",
        "axs[0].set_title('Distribution of Mobile Weight by Price Range')\n",
        "axs[0].set(xlabel='Price Range', ylabel='Density')\n",
        "\n",
        "# Plot 2: Box plot\n",
        "sns.boxplot(data=mp_df, x='price_range', y='mobile_wt', ax=axs[1])\n",
        "axs[1].set_title('Mobile Weight Box Plot by Price Range')\n",
        "axs[1].set(xlabel='Price Range', ylabel='Mobile Weight')\n",
        "\n",
        "# Adjusting the spacing between subplots\n",
        "plt.tight_layout()\n",
        "\n",
        "# Showing the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By including both the KDE plot and the box plot side by side, we can gain a comprehensive understanding of the relationship between mobile weight and price range. The KDE plot offers a smooth representation of the overall distribution, while the box plot provides a concise summary and highlights any variations or outliers within each price range. Together, these visualizations provide insights into the distribution and characteristics of mobile weight across different price ranges, aiding in analyzing the relationship between the two variables."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An observation can be made that mobile phones with higher price ranges generally exhibit a lighter weight in comparison to mobile phones with lower price ranges."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights gained from the analysis can have a positive impact on business by guiding product positioning and pricing strategies. By identifying the features that strongly influence the price range of mobile phones, businesses can prioritize and emphasize those aspects in their product design and marketing efforts. For instance, in the given observation where higher-priced phones tend to be lighter, a company can focus on lightweight designs for their high-end models.\n",
        "\n",
        "However, it is important to note that relying excessively on a single feature to determine pricing may have limitations and potentially hinder growth. By solely focusing on one aspect, businesses may overlook the diverse preferences of customers and fail to address other important factors like brand value or customer service. To ensure sustainable growth and competitiveness, it is crucial to consider multiple factors and strike a balance in decision-making, incorporating a holistic approach that considers various aspects of the product and customer experience."
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11 | MULTIVARIATE ANALYSIS :-"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Price Range Vs All Numerical Factor"
      ],
      "metadata": {
        "id": "PzbmrDO4mdCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "fig.suptitle('Price Range vs all numerical factor')\n",
        "sns.countplot(ax=axes[0, 0], data=mp_df, x='three_g',palette='dark:y')\n",
        "sns.countplot(ax=axes[0, 1], data=mp_df, x='touch_screen',palette='dark:salmon')\n",
        "sns.countplot(ax=axes[0, 2], data=mp_df, x='four_g',palette='dark:b')\n",
        "sns.countplot(ax=axes[1, 0], data=mp_df, x='wifi',palette='dark:g')\n",
        "sns.countplot(ax=axes[1,1], data = mp_df, x ='fc' ,palette='dark:y_r')\n",
        "sns.countplot(ax=axes[1,2], data = mp_df, x ='dual_sim',palette='dark:r' )\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I selected count plots for this analysis because they visually depict the distribution of categorical variables with respect to the price_range. By applying distinct color palettes to each plot, it's efficient to compare variable distributions across price ranges and uncover potential connections."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart illustrates how different categorical features, such as connectivity options (three_g, four_g, wifi), touch screen availability (touch_screen), and camera characteristics (fc, dual_sim), are distributed across various price ranges. This aids in identifying potential associations between these features and price segmentation."
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights can inform product strategies for positive business impact. However, a lack of popular features like four_g in lower-priced phones might hinder competitiveness and result in negative growth due to changing customer expectations."
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12 -  Correlation Heatmap"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking for multi-collinearity"
      ],
      "metadata": {
        "id": "0sCP0I9pnNRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code\n",
        "# Calculating the correlation matrix\n",
        "correlation = mp_df.corr()\n",
        "\n",
        "# Creating a heatmap of the correlation matrix\n",
        "plt.figure(figsize=[20, 15])\n",
        "sns.heatmap(correlation, cmap='viridis', annot=True, annot_kws={'fontsize': 10})\n",
        "plt.title('Correlation Heatmap',fontsize=20)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To assess the presence of multicollinearity."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There ia a strong correlation between RAM and price_range and it suggests that RAM plays a significant role in determining the price range of mobile phones."
      ],
      "metadata": {
        "id": "ZUFCSoaooPMZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "FKPmtY8npXIv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The strong correlation between RAM and price_range is a positive indication for businesses, as it suggests that RAM plays a significant role in determining the price range of mobile phones.\n",
        "\n",
        "However, there are instances of collinearity present in the data. Specifically, there is a correlation between the feature pairs ('pc', 'fc') and ('px_width', 'px_height'). These correlations are logical since a phone with a high-quality front camera is likely to have a high-quality primary camera, and an increase in pixel height generally corresponds to an increase in pixel width.\n",
        "\n",
        "To address this collinearity, one possible approach is to consider replacing the 'px_height' and 'px_width' features with a single feature representing the total number of pixels in the screen. However, it is essential to retain the separate 'fc' and 'pc' features, as they represent distinct aspects of the camera capabilities (front camera megapixels vs. primary camera megapixels) of the phone."
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on my chart experiments,I will define three hypothetical statements from the dataset. In the next three questions, I will perform hypothesis testing to obtain final conclusion about the statements through my code and statistical testing."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1\n",
        "All category phones are distributed with equal price range."
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null hypothesis (H0): All categories of phones are distributed with equal price range.\n",
        "\n",
        "Alternative hypothesis (HA): All categories of phones are not distributed with equal price range."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "observed_freq = pd.value_counts(mp_df['price_range']).values\n",
        "\n",
        "# Calculating expected frequency distribution\n",
        "total = len(mp_df)\n",
        "expected_freq = [total/4] * 4\n",
        "\n",
        "# Performing chi-square goodness-of-fit test\n",
        "chi2, p = stats.chisquare(observed_freq, f_exp=expected_freq)\n",
        "\n",
        "# Printing results\n",
        "print(f'Chi-square statistic: {chi2}, p-value: {p}')"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Chi-square goodness-of-fit test assesses if observed data fits an expected distribution. The p-value obtained represents the likelihood of the test statistic being as extreme as the sample's, assuming the null hypothesis is true. If p-value < 0.05, we reject the null, showing significant difference; if p-value ≥ 0.05, we retain the null, suggesting no significant difference."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I utilized the Chi-square goodness-of-fit test to compare observed and expected frequency distributions under the null hypothesis. Assuming equal price range distribution for all phone categories, I calculated expected frequencies and compared them with observed frequencies. The test statistic gauged the disparity, and the p-value indicated how likely the observed statistic was under the null. A p-value < 0.05 signaled significant difference, and ≥ 0.05 showed no strong evidence to reject the null. This made the Chi-square test fitting for this scenario."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2\n",
        "Approximately in 25% of the devices wifi is not available and in 75% of the devices wifi is available."
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H0): The proportion of times when wifi is not available is equal to or less than 0.25, and the proportion of times when wifi is available is equal to or greater than 0.75.\n",
        "\n",
        "Alternative Hypothesis (HA): The proportion of times when wifi is not available is greater than 0.25, or the proportion of times when wifi is available is less than 0.75."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Defining the null hypothesis proportion\n",
        "null_prop = 0.75\n",
        "\n",
        "# Defining the sample size\n",
        "n = 50\n",
        "\n",
        "# Calculating the probability of observing k devices with wifi availability\n",
        "k = range(0, n+1)\n",
        "null_probabilities = [stats.binom.pmf(x, n, null_prop) for x in k]\n",
        "\n",
        "# Printing the probability of observing exactly k devices with wifi availability\n",
        "for k_val, probability in zip(k, null_probabilities):\n",
        "    print(f\"k = {k_val}, probability = {probability}\")"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The proportion of devices with wifi availability is equal to 0.75.\n",
        "# The proportion of devices with wifi availability is not equal to 0.75.\n",
        "# Setting the significance level\n",
        "alpha = 0.05\n",
        "\n",
        "# Defining the sample size and number of devices with wifi availability\n",
        "n = 100\n",
        "num_with_wifi = 75\n",
        "\n",
        "# Performing the test\n",
        "test_result = smprop.proportions_ztest(num_with_wifi, n, value=0.75)\n",
        "\n",
        "# Extracting the test statistic and p-value\n",
        "test_stat, p_value = test_result\n",
        "\n",
        "# Printing the results\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis.\")\n",
        "\n",
        "print(\"Test statistic:\", test_stat)\n",
        "print(\"p-value:\", p_value)"
      ],
      "metadata": {
        "id": "P4X1dct-yjWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We used the one-sample proportion test to compare the sample's wifi availability proportion (25%) to the known population proportion (0.75). The resulting p-value indicates the likelihood of observing the sample proportion assuming the population proportion is 0.75. A p-value < 0.05 leads us to reject the null, indicating a significant difference, while ≥ 0.05 suggests no strong evidence for a significant distinction."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The one-sample proportion test was chosen due to its direct relevance to the research question on wifi availability proportion. With a known population proportion of 0.75 and a sample proportion of 0.25, this test is tailored for comparing proportions and evaluating statistical significance. By employing this test, we assessed the distinction between these proportions and made informed decisions on the null hypothesis. It was an apt choice to address the research inquiry based on available data."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3\n",
        "The proportion of 3G sim devices is approximately same across all price range."
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null hypothesis (H0): The proportion of devices with 3G sim is the same across all price ranges.\n",
        "\n",
        "Alternative hypothesis (HA): The proportion of devices with 3G sim is different across at least one pair of price ranges"
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Constructing the contingency table\n",
        "contingency_table = pd.crosstab(mp_df['price_range'], mp_df['three_g'])\n",
        "\n",
        "# Performing the chi-square test of independence\n",
        "chi2, p_value, dof, expected = stats.chi2_contingency(contingency_table)\n",
        "\n",
        "# Printing the contingency table, chi-square statistic, and p-value\n",
        "print(\"Contingency Table:\\n\", contingency_table)\n",
        "print(\"Chi-square statistic:\", chi2)\n",
        "print(\"p-value:\", p_value)"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I employed the chi-square test of independence to analyze the connection between price range and the presence of three G sims in devices. This test assesses the significance of association between categorical variables. By calculating the chi-square statistic and p-value, it evaluates the observed vs. expected frequencies under the null hypothesis of no association. A small p-value (<0.05) leads to rejecting the null, signifying significant association, while a large p-value (≥0.05) implies no significant link between variables. This approach helped assess the relationship and informed decisions on variable association."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chi-square test examines observed and expected frequencies in a contingency table. If the chi-square statistic is large and p-value < 0.05, we reject the null hypothesis, implying significant association.\n",
        "\n",
        "In this case, the p-value obtained (0.7117) is above 0.05. Thus, we retain the null hypothesis, signifying no strong evidence for a significant link between price_range and three_g variables."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "mp_df.isnull().sum()"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here I use isnull() method to check missing values,No missing values available."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "plt.figure(figsize=(15,15))\n",
        "\n",
        "# Define a color palette\n",
        "color_palette = sns.color_palette(\"pastel\")\n",
        "\n",
        "# Loop through each column in the DataFrame's describe() method\n",
        "for index, item in enumerate([i for i in mp_df.describe().columns.to_list()]):\n",
        "\n",
        "    # Creating a subplot in a 5x5 grid, starting with the first subplot (index 0)\n",
        "    plt.subplot(5, 5, index + 1)\n",
        "\n",
        "    # Creating a box plot of the current column's data with custom palette\n",
        "    sns.boxplot(mp_df[item], palette=color_palette)\n",
        "\n",
        "    # Add the column name to the subplot title\n",
        "    plt.title(item)\n",
        "\n",
        "    # Add some spacing between the subplots\n",
        "    plt.subplots_adjust(hspace=0.5)\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "# Display the plots\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since there aren't many outliers present, there is no need to perform extensive experimentation."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Categorical encoding is not required as all the values are already in either integer or float format."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Textual Data Preprocessing is not required."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Manipulation & Selection is not required in our dataset."
      ],
      "metadata": {
        "id": "xaw5MmA5jSeU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data\n",
        "# Selecting features to avoid overfitting\n",
        "\n",
        "# Defining X and y\n",
        "mp_df.drop(['px_height', 'px_width'], axis = 1, inplace = True)\n",
        "\n",
        "X = mp_df.drop(['price_range'], axis = 1)\n",
        "y = mp_df['price_range']"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have decided to remove the variables px_height and px_width from my data because they have minimal impact on the dependent variable, which is the price range."
      ],
      "metadata": {
        "id": "nP5-j9kujk_M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here I employ MinMaxScaler from Scikit-learn to scale variable X. This technique transforms data to a specified range (usually 0 to 1) by subtracting the minimum value and dividing by the range (max-min). MinMaxScaler suits cases with unknown or non-normal data distributions and handles outliers better than other scaling methods."
      ],
      "metadata": {
        "id": "PK_jy_UmjvB9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no need to do dimensionality reduction."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "# Defining X and y\n",
        "X = mp_df.drop(['price_range'], axis = 1)\n",
        "y = mp_df['price_range']"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding the shape of X and y\n",
        "print(f'shape of x is - {X.shape}')\n",
        "print(f'shape of y is - {y.shape}')"
      ],
      "metadata": {
        "id": "RIvs72Slj9le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.20, random_state = 42)\n",
        "# Finding X_train and y_train shape\n",
        "print(f'shape of X_train is - {X_train.shape}')\n",
        "print(f'shape of y_train is - {y_train.shape}')"
      ],
      "metadata": {
        "id": "KN0myquwkCe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The choice of data splitting ratio depends on various factors, including the size of the dataset, the availability of labeled data, the complexity of the problem, and the specific requirements of the task.\n",
        "\n",
        "However, in general, common data splitting ratios are often used in machine learning projects. One common practice is to use an 80-20 or 70-30 split for the training and testing sets. That means allocating 70% or 80% of the data for training the model and reserving the remaining 30% or 20% for testing and evaluation."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no Imbalanced Data."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1 | Logistic Regression"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "log_reg = LogisticRegression()\n",
        "# Fit the Algorithm\n",
        "log_reg.fit(X_train, y_train)\n",
        "# Predict on the model\n",
        "y_pred_test = log_reg.predict(X_test)\n",
        "y_pred_train = log_reg.predict(X_train)\n",
        "\n",
        "print('Classification report for Logistic Regression (Test set)= ')\n",
        "print(classification_report(y_pred_test, y_test))\n",
        "# Generating the confusion matrix\n",
        "cf_matrix = confusion_matrix(y_test, y_pred_test)\n",
        "\n",
        "print(cf_matrix)\n",
        "\n",
        "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
        "\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "# Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels([0,1,2,3])\n",
        "ax.yaxis.set_ticklabels([0,1,2,3])\n",
        "\n",
        "# Displaying the visualization of the Confusion Matrix\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Evaluation metrics for train\n",
        "print('Classification report for Logistic Regression (Train set)= ')\n",
        "print( classification_report(y_pred_train, y_train))"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Logistic Regression model's classification report includes precision, recall, and F1-score for each class, along with support (instances count). Precision is the ratio of accurate positive predictions to total positive predictions, while recall is the ratio of accurate positive predictions to actual positives. F1-score balances precision and recall. The model achieved 83% accuracy on the training set, with similar scores for each class. The macro and weighted averages are both 83%. This indicates a reasonable model performance, yet further assessment on overfitting, underfitting, and test set performance is essential."
      ],
      "metadata": {
        "id": "kGipzSqqyPKL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "log_reg = LogisticRegression()\n",
        "scores = cross_val_score(log_reg, X_scaled, y, cv=5)\n",
        "\n",
        "print(\"Cross-validation scores:\", scores)\n",
        "print(\"Average cross-validation score:\", np.mean(scores))\n",
        "\n",
        "\n",
        "log_reg = LogisticRegression()\n",
        "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
        "grid = GridSearchCV(log_reg, param_grid, cv=5)\n",
        "# Fit the Algorithm\n",
        "grid.fit(X_scaled, y)\n",
        "# Predict on the model\n",
        "print(\"Best cross-validation score:\", grid.best_score_)\n",
        "print(\"Best parameters:\", grid.best_params_)\n",
        "print(\"Test set score:\", grid.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearchCV is a method for hyperparameter optimization in machine learning. It systematically explores a predefined hyperparameter grid to find the best combination for optimal model performance. It was chosen here to optimize the C hyperparameter in the logistic regression model, ensuring enhanced results on the validation set."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The logistic regression model demonstrated strong performance with a cross-validation score of 0.82. The optimal C value of 10 resulted in a consistent test set score of 0.82, suggesting minimal overfitting. This indicates the model's suitability for the dataset. Additional evaluation of precision, recall, and F1-score would provide a comprehensive view of its performance."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2  | Random Forest"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 2 Implementation\n",
        "rfc=RandomForestClassifier(n_estimators=200)\n",
        "# Fit the Algorithm\n",
        "rfc.fit(X_train, y_train)\n",
        "# Making the Prediction\n",
        "y_pred = rfc.predict(X_test)\n",
        "test_score= accuracy_score(y_test, y_pred)\n",
        "test_score\n",
        "y_pred_train = rfc.predict(X_train)\n",
        "train_score = accuracy_score(y_train, y_pred_train)\n",
        "train_score\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "FM011_pA0yKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating the confusion matrix\n",
        "cf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(cf_matrix)\n",
        "\n",
        "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
        "\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "# Ticket labels\n",
        "ax.xaxis.set_ticklabels([0,1,2,3])\n",
        "ax.yaxis.set_ticklabels([0,1,2,3])\n",
        "\n",
        "# Displaying the visualization of the Confusion Matrix\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "naRrOXkO1ITu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importance = pd.DataFrame({'Feature':X.columns,\n",
        "                                   'Score':rfc.feature_importances_}).sort_values(by='Score', ascending=False).reset_index(drop=True)\n",
        "feature_importance.head()"
      ],
      "metadata": {
        "id": "ng13AQpP1S_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(15,8))\n",
        "ax = sns.barplot(x=feature_importance['Score'], y=feature_importance['Feature'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "80XrCjLZ1XlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Random Forest classification model achieved an accuracy of 0.80. Its precision, recall, and F1-score ranged from 0.68 to 0.92 for different classes, indicating moderate overall performance in correctly predicting class labels."
      ],
      "metadata": {
        "id": "w9ab3C-G1cHY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "params = {'n_estimators':[10,50],\n",
        "          'max_depth':[10,20],\n",
        "           'min_samples_split':[2,4],\n",
        "          'max_features':['sqrt','log2'],\n",
        "          'max_leaf_nodes':[10, 20]\n",
        "          }\n",
        "rf = RandomForestClassifier()\n",
        "clsr = GridSearchCV(rf, params, scoring='accuracy', cv=3)\n",
        "# Fit the Algorithm\n",
        "clsr.fit(X, y)\n",
        "# Predict on the model\n",
        "print(f'best_params_ : {clsr.best_params_}')\n",
        "print(f'best_estimator_ : {clsr.best_estimator_}')\n",
        "print(f'best_score_ : {clsr.best_score_}')"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "clsr = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
        "                       criterion='gini', max_depth=30, max_features='log2',\n",
        "                       max_leaf_nodes=40, max_samples=None,\n",
        "                       min_impurity_decrease=0.0,\n",
        "                       min_samples_leaf=1, min_samples_split=4,\n",
        "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
        "                       n_jobs=None, oob_score=False, random_state=None,\n",
        "                       verbose=0, warm_start=False)\n",
        "clsr.fit(X_train, y_train)\n",
        "# making prediction\n",
        "y_pred = clsr.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "snG68emp1qMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating the confusion matrix\n",
        "cf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(cf_matrix)\n",
        "\n",
        "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
        "\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "# Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels([0,1,2,3])\n",
        "ax.yaxis.set_ticklabels([0,1,2,3])\n",
        "\n",
        "# Displaying the visualization of the Confusion Matrix.\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6LrloEG81zbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clsr.predict(X_train)\n",
        "accuracy_score(y_train, y_pred)"
      ],
      "metadata": {
        "id": "i-N8lQqA13xY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_train, y_pred))"
      ],
      "metadata": {
        "id": "Wqp0NKsR171n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importance = pd.DataFrame({'Feature':X.columns,\n",
        "                                   'Score':clsr.feature_importances_}).sort_values(by='Score', ascending=False).reset_index(drop=True)\n",
        "feature_importance.head()"
      ],
      "metadata": {
        "id": "5wwXSkti1--A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used GridSearchCV, a powerful hyperparameter optimization technique. This approach systematically explores hyperparameter values for an estimator, leveraging cross-validation to evaluate each combination. By automating parameter tuning, GridSearchCV identifies the best hyperparameters, enhancing model performance."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model's performance has improved slightly, with accuracy increasing from 0.80 to 0.81 and weighted average F1-score improving from 0.80 to 0.81. While precision and recall scores have generally increased, the macro average scores remain unchanged. Overall, there's a modest enhancement in the model's performance."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The evaluation metrics include class-specific precision, recall, and F1-score, along with the weighted average and macro average. The weighted average considers class imbalance, providing an overall assessment of model performance. The macro average assesses each class individually. The confusion matrix identifies misclassifications for a deeper understanding. These metrics collectively offer valuable insights into the model's impact on business performance.\n",
        "\n"
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3 | XGBoost"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "xgb = XGBClassifier(max_depth = 5, learning_rate = 0.1)\n",
        "# Fit the Algorithm\n",
        "xgb.fit(X_train, y_train)\n",
        "\n",
        "XGBClassifier(max_depth=5, objective='multi:softprob')\n",
        "# Predict on the model\n",
        "y_pred_train = xgb.predict(X_train)\n",
        "y_pred_test = xgb.predict(X_test)"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrics for test\n",
        "score = classification_report(y_test, y_pred_test)\n",
        "print('Classification Report for XGBoost(Test set)= ')\n",
        "print(score)"
      ],
      "metadata": {
        "id": "YMmjttrz4SuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "score = classification_report(y_train, y_pred_train)\n",
        "print('Classification Report for XGBoost(Train set)= ')\n",
        "print(score)"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The XGBoost model demonstrated exceptional performance on the training set, with an accuracy score of 0.99. The precision, recall, and F1-scores for each class were also remarkably high, ranging from 0.99 to 1.00. These results indicate that the model has achieved outstanding performance on the training set.\n",
        "\n",
        "The macro average and weighted average F1-scores were also very high, suggesting that the model generalizes well across all classes and does not exhibit bias towards any specific class.\n",
        "\n",
        "In summary, the XGBoost model showcases outstanding performance on the training set, with nearly perfect scores across all evaluation metrics. Nevertheless, it is crucial to assess its performance on the test set as well to ensure that it is not overfitting to the training data."
      ],
      "metadata": {
        "id": "8TBvAick4CsC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 2 Implementation\n",
        "xgb = XGBClassifier()\n",
        "# Defining the hyperparameter search space\n",
        "params = {\n",
        "    'max_depth': [3, 5],\n",
        "    'learning_rate': [0.1, 0.01],\n",
        "    'n_estimators': [50, 100],\n",
        "}\n",
        "\n",
        "# Performing cross-validation and hyperparameter tuning\n",
        "grid_search = GridSearchCV(xgb, params, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train,y_train)\n",
        "\n",
        "# Printing the best hyperparameters and CV score\n",
        "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
        "print(\"Cross-validation score:\", grid_search.best_score_)\n",
        "\n",
        "# Evaluating the tuned model on the test set\n",
        "y_pred_test = grid_search.predict(X_test)\n",
        "score = classification_report(y_test, y_pred_test)\n",
        "print('Classification Report for XGBoost(Test set)= ')\n",
        "print(score)"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating the confusion matrix\n",
        "cf_matrix = confusion_matrix(y_test, y_pred_test)\n",
        "\n",
        "print(cf_matrix)\n",
        "\n",
        "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
        "\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "# Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels([0,1,2,3])\n",
        "ax.yaxis.set_ticklabels([0,1,2,3])\n",
        "\n",
        "# Displaying the visualization of the Confusion Matrix.\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ds91pZFk4hnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrics for train\n",
        "\n",
        "score = classification_report(y_train, y_pred_train)\n",
        "print('Classification Report for tuned XGBoost(Train set)= ')\n",
        "print(score)"
      ],
      "metadata": {
        "id": "i59vsG1M4nwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The hyperparameter optimization technique employed in this scenario is RandomizedSearchCV from scikit-learn's model_selection module. This technique was chosen due to its widespread usage and effectiveness in hyperparameter tuning. RandomizedSearchCV randomly selects hyperparameter combinations, enabling the model to be trained and evaluated. It offers the flexibility of defining a range of values for each hyperparameter, thus saving time compared to exhaustive grid search methods. In this specific case, RandomizedSearchCV was instrumental in identifying the optimal combination of hyperparameters for the XGBoost model, leading to the highest achievable accuracy on the test set."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After applying hyperparameter tuning and cross-validation, the performance of the XGBoost model demonstrated improvement. The cross-validation score increased from 0.815 to 0.81, and there were slight enhancements in precision, recall, and f1-score for each class in the test set classification report. Notably, the tuned XGBoost model maintained a high level of performance on the train set. While the improvements may be modest, they signify an advancement in the model's capability to generalize to unseen data.\n"
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used Classification Report, Accuracy Score and Confusion Matrix  These metrics offer insights into the model's performance and its ability to make accurate predictions. i opted for Confusion Matrix as it visualizes the model's performance in terms of true positives, true negatives, false positives, and false negatives.It offers insights into the types of errors the model is making, which can be vital for making informed decisions and adjusting strategies."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I opted for XGBoost and random forest models as they outperformed the random forest regression in terms of prediction accuracy and results."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I can use a model explainability tool to describe and illustrate the logistic regression and XGBoost models, as well as highlight the significance of features in the prediction process.\n",
        "\n",
        "Logistic regression is a linear classification algorithm that estimates the probability of a binary outcome, such as mobile phone price range, based on input features. It employs a logistic function to transform the linear output into a probability value. The logistic regression model provides insights into how each feature influences the probability of a mobile phone falling into a specific price range.\n",
        "\n",
        "On the contrary, XGBoost is a potent ensemble learning algorithm based on decision trees. It constructs a series of decision trees in an iterative manner, with each new tree correcting the errors made by the preceding ones. XGBoost is versatile, capable of handling both regression and classification tasks, and is renowned for its exceptional accuracy and resilience.\n",
        "\n",
        "To elucidate the feature importance of the logistic regression and XGBoost models, we can utilize the SHAP (SHapley Additive exPlanations) model explainability tool. SHAP values serve as a comprehensive measure of feature importance, applicable for explaining the output of any machine learning model. Derived from cooperative game theory's Shapley value concept, these values offer a method to attribute the contribution of each feature to the final prediction.\n"
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "EDA Insights :\n",
        "\n",
        "1. For Bluethooth variable half the devices have Bluetooth, and half don’t\n",
        "\n",
        "2. There is a gradual increase in battery as the price range increases\n",
        "\n",
        "3. Ram has continuous increase with price range while moving from Low cost to Very high cost\n",
        "\n",
        "4. Costleir phones are lighter\n",
        "\n",
        "5. RAM, battery power, pixels played more significant role in deciding the price range of mobile phone.\n",
        "\n",
        "Model Insights :\n",
        "\n",
        "For Mobile price range prediction we have used\n",
        "\n",
        "1.Logistic Regression\n",
        "\n",
        "2.Random Forest\n",
        "\n",
        "3.XGBoost\n",
        "\n",
        "From the implemented models the best-performing model  is Logistic Regression. Here are the reasons:\n",
        "\n",
        "Logistic Regression achieved the highest accuracy of 0.90, indicating that it correctly predicted the class labels for a significant portion of the test data.\n",
        "\n",
        "The precision, recall, and F1-score for each class in the Logistic Regression classification report are generally high, indicating a good balance between correctly identifying positive and negative instances for each class.\n",
        "\n",
        "While Random Forest also achieved good accuracy scores, the evaluation metrics, such as precision, recall, and F1-score, for Logistic Regression appear to be slightly better.\n",
        "\n",
        "1.Logistic Regression\n",
        "\n",
        "accuracy 0.90 500 macro avg 0.90 0.90 0.90 500 weighted avg 0.91 0.90 0.90 500\n",
        "\n",
        "2.Random Forest\n",
        "\n",
        "accuracy 0.89 500 macro avg 0.89 0.89 0.89 500 weighted avg 0.89 0.89 0.89 500\n",
        "\n",
        "** Random Forrest cross validation results **\n",
        "\n",
        "accuracy 0.86 600 macro avg 0.86 0.86 0.86 600 weighted avg 0.86 0.86 0.86 600\n",
        "\n",
        "3.XGBoost\n",
        "\n",
        "XGBoost is a potent ensemble learning algorithm based on decision trees. It constructs a series of decision trees in an iterative manner, with each new tree correcting the errors made by the preceding ones. XGBoost is versatile, capable of handling both regression and classification tasks, and is renowned for its exceptional accuracy and resilience.\n",
        "\n",
        "accuracy 0.81  400  macro avg 0.80  0.80  0.80  400 weighted avg  0.81      0.81      0.81       400"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}