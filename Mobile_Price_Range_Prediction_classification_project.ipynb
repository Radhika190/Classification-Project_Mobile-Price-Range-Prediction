{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Radhika190/Classification-Project_Mobile-Price-Range-Prediction/blob/main/Mobile_Price_Range_Prediction_classification_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -\n",
        "\n",
        "**Mobile Price Range Prediction**"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Project Type**    - Unsupervised\n",
        "##### **Contribution**    - Individual\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Within the competitive mobile phone market, companies aim to decode mobile phone sales data and the influencing factors on prices. The goal is to establish connections between mobile phone features like RAM, Internal Memory, etc., and their respective price categories, indicating varying price levels. The objective is to identify price ranges.\n",
        "\n",
        "In this project, first we do Exploratory Data Analysis on the data set. We look for missing data values,duplicates values (none were found) and outliers and appropriately modify them. we have seen relation b/w numeric features and dependent variables and seen different price range in the terms of ram,bluetooth supported or not, battery power, wifi supported or not etc.We checked the data is balanced or not, We also perform correlation analysis to extract out the important and relevant feature set and later perform feature engineering to modify few existing columns and drop out irrelavant ones.we normilized the independent features through mini-max scaler and later we have done hypothesis testing where we find out the p value using F-test and seen whether the null hypothesis is rejected or not.\n",
        "\n",
        "We then look at several popular individual models from simple ones like Logistic regression for multiclass data, to more complicated ensemble ones like Decision Tree, Random Forest, XG Boost, Naive Bayes, KNN, Support vector machine and find out best model through the highest accuracy for the business deployment.\n"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/Radhika190/Classification-Project_Mobile-Price-Range-Prediction"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the compitive mobile phone market in the compinies want to understand sales data of mobile phones and factors which drive the prices. The objective is to find out some relation between features of a mobile phone (eg. Ram, Internal memory etc.) and Its selling price. In this problem, we do not have to predict the actual price but a price range indecating how high the price."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from scipy import stats\n",
        "import statsmodels.stats.proportion as smprop\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mp_df = pd.read_csv('/content/drive/MyDrive/ML PROJECT/Ml classification Project/data_mobile_price_range.csv')"
      ],
      "metadata": {
        "id": "v1rcF0r-Ogpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "mp_df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mp_df.tail()"
      ],
      "metadata": {
        "id": "8Pdjt1n5QBLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "print(\"Rows: \" + str(len(mp_df.axes[0])))\n",
        "print(\"Columns: \" + str(len(mp_df.axes[1])))"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "mp_df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "mp_df.duplicated().sum()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "mp_df.isna().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "plt.figure(figsize=(13, 5))\n",
        "sns.heatmap(mp_df.isnull(), cbar=True, yticklabels=False,cmap=\"pink\")\n",
        "plt.xlabel(\"column_name\", size=14, weight=\"bold\")\n",
        "plt.title(\"missing values in column\",fontweight=\"bold\",size=17)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. The dataset has 2000 rows and 21 columns.\n",
        "2. There are no Duplicate and Null values in the dataset."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "mp_df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "mp_df.describe().T"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Battery_power - Total energy a battery can store in one time measured in mAh\n",
        "\n",
        "2. Blue - Has bluetooth or not,\n",
        "\n",
        "3. Clock_speed - speed at which microprocessor executes instructions,\n",
        "\n",
        "4. Dual_sim - Has dual sim support or not,\n",
        "\n",
        "5. Fc - Front Camera mega pixels,\n",
        "\n",
        "6. Four_g - Has 4G or not,\n",
        "\n",
        "7. Int_memory - Internal Memory in Gigabytes,\n",
        "\n",
        "8. M_dep - Mobile Depth in cm,\n",
        "\n",
        "9. Mobile_wt - Weight of mobile phone,\n",
        "\n",
        "10. N_cores - Number of cores of processor,\n",
        "\n",
        "11. Pc - Primary Camera mega pixels,\n",
        "\n",
        "12. Px_height - Pixel Resolution Height,\n",
        "\n",
        "13. Px_width - Pixel Resolution Width,\n",
        "\n",
        "14. Ram - Random Access Memory in Mega,\n",
        "\n",
        "15. Touch_screen - Has touch screen or not,\n",
        "\n",
        "16. Wifi - Has wifi or not,\n",
        "\n",
        "17. Sc_w - Screen Width of mobile in cm,\n",
        "\n",
        "18. Talk_time - longest time that a single battery charge will last when you are over a call\n",
        "\n",
        "19. Three_g - Has 3G or not,\n",
        "\n",
        "20. Wifi - Has wifi or not,\n",
        "\n",
        "21. Price_range - This is the target variable with value of 0(low cost), 1(medium cost),2(high cost) and 3(very high cost)."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "# Checking the total number of Unique Values for each variable\n",
        "mp_df.nunique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "\n",
        "# It is not logical for a phone screen width or pixel height to have a value of 0, so we need to make sure to verify and address such instances to prevent any complications in our analysis\n",
        "# Count of phones with sc_w = 0\n",
        "screen_width_0_count = sum(mp_df.sc_w == 0)\n",
        "print(f\"Number of phones with sc_w = 0: {screen_width_0_count}\")\n",
        "\n",
        "# Count of phones with px_height = 0\n",
        "px_height_0_count = sum(mp_df.px_height == 0)\n",
        "print(f\"Number of phones with px_height = 0: {px_height_0_count}\")"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replacing 0 values with the mean value\n",
        "sc_w_mean = mp_df.sc_w.mean()\n",
        "px_height_mean = mp_df.px_height.mean()\n",
        "\n",
        "mp_df.sc_w = np.where(mp_df.sc_w == 0, sc_w_mean, mp_df.sc_w)\n",
        "mp_df.px_height = np.where(mp_df.px_height == 0, px_height_mean, mp_df.px_height)\n",
        "\n",
        "# Printing the updated dataframe\n",
        "print(mp_df)"
      ],
      "metadata": {
        "id": "53A1oEQ2vAlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for the 0 values in the sc_w and px_height columns after the data wrangling\n",
        "\n",
        "# Count of phones with sc_w = 0\n",
        "sc_w_zero_count = sum(mp_df.sc_w == 0)\n",
        "print(f\"Number of phones with sc_w = 0: {sc_w_zero_count}\")\n",
        "\n",
        "# Count of phones with px_height = 0\n",
        "px_height_zero_count = sum(mp_df.px_height == 0)\n",
        "print(f\"Number of phones with px_height = 0: {px_height_zero_count}\")\n"
      ],
      "metadata": {
        "id": "O5oAwlC-vaF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  I discovered that there are 2 phones in the dataset with a pixel height value of 0, and 180 phones with a screen width value of 0.\n",
        "\n",
        "* It is illogical for a phone screen width or pixel height to have a value of 0, so it is necessary to identify and address these instances properly to prevent any potential problems in our analysis.\n",
        "\n",
        "* The 0 values in the dataset have been replaced with their respective column mean values, ensuring that there are no longer any missing values in the table. Therefore, our data is now prepared for data analysis."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "mob_price_range=mp_df['price_range'].value_counts().plot.pie(explode=[0.1, 0, 0.1, 0],labels= ['Low Cost', 'Medium cost', 'High Cost', 'Very High Cost'],\n",
        "                                                             autopct='%1.1f%%',startangle=180,shadow=True,figsize=(11,6),fontsize=11,\n",
        "                                                             colors=['skyblue', 'lightcoral', 'lightgreen', 'pink'])\n",
        "plt.title('price range distribution')"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pie charts typically show relative proportions of different categories in a data set."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Different categories of price range of phones have equal percentage of distribution in the data set"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above found insights, we can assume that every category of phone are equally distributed, perhaps the demand for them are equal."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.histplot(mp_df[\"battery_power\"], color='blue', bins=20)  # Using histplot for better formatting\n",
        "plt.xlabel('Battery Power')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Battery Power')\n",
        "plt.grid(axis='y', alpha=0.75)\n",
        "sns.despine()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "displot() is a useful tool for visualizing and exploring the distribution of a single variable or multiple variables in a dataset."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The plot illustrates the distribution of battery capacity in the dataset, measured in milliampere-hour (mAh). It can be observed that the distribution of battery capacity is almost uniform, with a slightly higher frequency in the lower battery power range. This implies that lower-end phones are sold more frequently than higher-end ones."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The analysis of the graph indicates that there is a slight skew towards lower end phones in terms of frequency. This suggests that lower end phone models are produced more frequently. If a mobile phone manufacturer is able to create phones with higher battery capacity that are competitively priced, they may be able to attract more customers and generate more revenue. This information could also be used to guide marketing and advertising strategies, as companies can focus on promoting the battery capacity of their phones as a key selling point to potential customers."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "color_palette = sns.color_palette('Set2')\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "mp_df['wifi'].value_counts().plot.pie(\n",
        "    autopct='%1.1f%%',\n",
        "    colors=color_palette,\n",
        "    shadow=True,\n",
        "    labeldistance=None,\n",
        "    explode=[0., 0.]  # Add explode for visual separation\n",
        ")\n",
        "\n",
        "# Adding title, legend, and labels\n",
        "plt.title('Distribution by Price Range for Wi-Fi Support')\n",
        "plt.legend(['Supports Wi-Fi', 'Does Not Support Wi-Fi'], loc='upper right')\n",
        "\n",
        "# Removing y-axis label\n",
        "plt.ylabel('')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pie chart shows the percentage value of the Wifi avalability in the phone."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Avalability of the Wifi and their speed plays an important role in the mobile price."
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Customers looking for the avalability of Wifi in phones, this impacts the price range of the phone."
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BIVARIATE ANALYSIS :**"
      ],
      "metadata": {
        "id": "xcaB7PuiwWcQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.pointplot(y=\"pc\", x=\"price_range\", data=mp_df)"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Column charts explains the requirement ."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Be it the rear camera or the front camera , the price range varies accordingly with the features."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Camera is the feature very Customer is interested in the phones ,so this is the positive impact to the business"
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "sns.set_style('whitegrid')\n",
        "average_ram_by_price = mp_df.groupby('price_range')['ram'].mean()\n",
        "plt.figure(figsize=(8, 6))\n",
        "barplot = average_ram_by_price.plot(kind='bar', color='coral')\n",
        "plt.title('Average RAM for Each Price Range')\n",
        "plt.xlabel('Price Range')\n",
        "plt.ylabel('Average RAM')\n",
        "plt.grid(axis='y', alpha=0.75)\n",
        "barplot.set_xticklabels(['Low Cost', 'Medium Cost', 'High Cost', 'Very High Cost'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Price ranges can be understood properly in this chart."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ram plays the major role in the price range ,higher the RAM higher is the price range of the phone"
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Customers look for the speed ,multitasking phones in this generation , where in RAM plays the role resulting in costlier phones ."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "# Grouping the data by price range and dual sim and counting the number of devices in each group\n",
        "sim_count = mp_df.groupby(['price_range', 'dual_sim']).size().unstack()\n",
        "color_palette = ['lightblue', 'lightgreen']\n",
        "# Plotting a stacked bar chart of the dual sim count for each price range\n",
        "sim_count.plot(kind = 'bar', stacked = True, color=color_palette)\n",
        "\n",
        "# Adding axis labels and a title\n",
        "plt.xlabel('Price Range')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Number of Dual SIM Devices by Price Range')\n",
        "\n",
        "# Showing the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The sim_count.plot(kind='bar', stacked=True) line of code is used to create a stacked bar chart. This type of chart is suitable for visualizing the count or frequency of different categories within each price range."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can observe that for low, medium and high price range the count of mobile phones having dual sim and those which do not have are nearly the same while the count of devices having dual sim is higher than those that don't have in very high price range devices."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, the insight is useful since, we observe that very high price range devices have a higher number of dual sim phones, and other ranges also have a significant number of dual sim phones as well. Based on this information, businesses may in future pay attention to this feature before going for production of new models of mobile phones"
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "# price range and talk time\n",
        "plt.figure(figsize=(14,6))\n",
        "sns.barplot(data = mp_df , x ='talk_time' , y= 'price_range' )"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose the bar plot for comparing price_range and talk_time because it effectively displays the average talk_time for each price range category, allowing easy comparison of how talk time varies across different price segments."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart reveals that there is no significant variation in average talk time across different price ranges. This suggests that the price of a mobile phone may not strongly influence its talk time capability."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights highlight a positive aspect: talk time appears consistent across price ranges, indicating that customers can expect good battery performance regardless of their budget. This consistency can enhance customer satisfaction and contribute to positive brand perception."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MULTIVARIATE ANALYSIS :**"
      ],
      "metadata": {
        "id": "bJf93QM5AiED"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "col_palette = sns.color_palette('Set2')\n",
        "\n",
        "networks = ['four_g', 'three_g']\n",
        "for dataset in networks:\n",
        "    fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(15, 8))\n",
        "\n",
        "    # Pie chart\n",
        "    mp_df[dataset].value_counts().plot.pie(\n",
        "        autopct='%1.1f%%',\n",
        "        ax=ax1,\n",
        "        colors=col_palette,\n",
        "        shadow=True,\n",
        "        labeldistance=None,\n",
        "        explode=[0.05, 0.05]  # Add explode for visual separation\n",
        "    )\n",
        "    ax1.set_title('Distribution by Price Range')\n",
        "    ax1.legend(['Supports', 'Does Not Support'])\n",
        "\n",
        "    # Count plot\n",
        "    sns.countplot(x=dataset, hue='price_range', data=mp_df, ax=ax2, palette='rocket_r')\n",
        "    ax2.set_title('Distribution by Price Range')\n",
        "    ax2.set_xlabel(dataset)\n",
        "    ax2.set_ylabel('Count')\n",
        "    ax2.legend(['Low Cost', 'Medium Cost', 'High Cost', 'Very High Cost'])\n",
        "    ax2.set_xticklabels(['Does Not Support', 'Support'])\n",
        "\n",
        "    # Adjust subplot spacing\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Display the plots\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pie chart shows the percentage value of the network avalability in the phone\n",
        "\n",
        "While columns chart explains price distirbutions according to their supportivity."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Avalability of the Network and their speed plays in role in the price range."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Customers lookin for the good network phones this impacts the price range of the phone."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "sns.set_style(\"darkgrid\")\n",
        "\n",
        "# Creating a subplots\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, figsize=(8, 10))\n",
        "\n",
        "# Line plot for pixel width\n",
        "mp_df.groupby('price_range')['px_width'].mean().plot(kind='line', color='red', ax=ax1)\n",
        "ax1.set_title('Average Pixel Width and Height by Price Range')\n",
        "ax1.set_xlabel('Price Range')\n",
        "ax1.set_ylabel('Average Pixel Width')\n",
        "ax1.set_xticks([0, 1, 2, 3])\n",
        "ax1.set_xticklabels(['Low Cost', 'Medium Cost', 'High Cost', 'Very High Cost'])\n",
        "\n",
        "# Line plot for pixel height\n",
        "mp_df.groupby('price_range')['px_height'].mean().plot(kind='line', color='blue', ax=ax2)\n",
        "ax2.set_xlabel('Price Range')\n",
        "ax2.set_ylabel('Average Pixel Height')\n",
        "ax2.set_xticks([0, 1, 2, 3])\n",
        "ax2.set_xticklabels(['Low Cost', 'Medium Cost', 'High Cost', 'Very High Cost'])\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Price ranges can be understood properly in this chart."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Price ranges linearly increases in both pixel height and width of the phone."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is clear from the graph that both the features help in price range of the phones."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "# Price Range vs all numerical factor\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "fig.suptitle('Price Range vs all numerical factor')\n",
        "sns.countplot(ax=axes[0, 0], data=mp_df, x='three_g',palette='Reds')\n",
        "sns.countplot(ax=axes[0, 1], data=mp_df, x='touch_screen',palette='Reds')\n",
        "sns.countplot(ax=axes[0, 2], data=mp_df, x='four_g',palette='Reds')\n",
        "sns.countplot(ax=axes[1, 0], data=mp_df, x='wifi',palette='Reds')\n",
        "sns.countplot(ax=axes[1,1], data = mp_df, x ='fc' ,palette='Reds')\n",
        "sns.countplot(ax=axes[1,2], data = mp_df, x ='dual_sim',palette='Reds' )\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I selected count plots for this analysis because they visually depict the distribution of categorical variables with respect to the price_range. By applying distinct color palettes to each plot, it's efficient to compare variable distributions across price ranges and uncover potential connections."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart illustrates how different categorical features, such as connectivity options (three_g, four_g, wifi), touch screen availability (touch_screen), and camera characteristics (fc, dual_sim), are distributed across various price ranges. This aids in identifying potential associations between these features and price segmentation."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights can inform product strategies for positive business impact. However, a lack of popular features like four_g in lower-priced phones might hinder competitiveness and result in negative growth due to changing customer expectations."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "# Calculating the correlation matrix\n",
        "correlation = mp_df.corr()\n",
        "\n",
        "# Creating a heatmap of the correlation matrix\n",
        "plt.figure(figsize=[20, 15])\n",
        "sns.heatmap(correlation, cmap='coolwarm', annot=True, annot_kws={'fontsize': 10})\n",
        "plt.title('Correlation Heatmap',fontsize=20)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To assess the presence of multicollinearity."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The strong positive correlation between RAM and price_range indicates that RAM significantly influences mobile phone price range. However, collinearity exists between pairs like ('pc', 'fc') and ('px_width', 'px_height'). This is reasonable, as a better front camera usually implies a better primary camera, and pixel height correlates with pixel width.\n",
        "\n",
        "To address collinearity, one option is to replace 'px_height' and 'px_width' with a combined pixel count. However, 'fc' and 'pc' should be retained as they represent separate camera features."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on my chart experiments,I will define three hypothetical statements from the dataset. In the next three questions, I will perform hypothesis testing to obtain final conclusion about the statements through my code and statistical testing."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1\n",
        "All category phones are distributed with equal price range."
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null hypothesis (H0): All categories of phones are distributed with equal price range.\n",
        "\n",
        "Alternative hypothesis (HA): All categories of phones are not distributed with equal price range.\n"
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "observed_freq = pd.value_counts(mp_df['price_range']).values\n",
        "\n",
        "# Calculating expected frequency distribution\n",
        "total = len(mp_df)\n",
        "expected_freq = [total/4] * 4\n",
        "\n",
        "# Performing chi-square goodness-of-fit test\n",
        "chi2, p = stats.chisquare(observed_freq, f_exp=expected_freq)\n",
        "\n",
        "# Printing results\n",
        "print(f'Chi-square statistic: {chi2}, p-value: {p}')"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Chi-square goodness-of-fit test assesses if observed data fits an expected distribution. The p-value obtained represents the likelihood of the test statistic being as extreme as the sample's, assuming the null hypothesis is true. If p-value < 0.05, we reject the null, showing significant difference; if p-value  0.05, we retain the null, suggesting no significant difference."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I utilized the Chi-square goodness-of-fit test to compare observed and expected frequency distributions under the null hypothesis. Assuming equal price range distribution for all phone categories, I calculated expected frequencies and compared them with observed frequencies. The test statistic gauged the disparity, and the p-value indicated how likely the observed statistic was under the null. A p-value < 0.05 signaled significant difference, and  0.05 showed no strong evidence to reject the null. This made the Chi-square test fitting for this scenario."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2\n",
        "Approximately in 25% of the devices wifi is not available and in 75% of the devices wifi is available."
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H0): The proportion of times when wifi is not available is equal to or less than 0.25, and the proportion of times when wifi is available is equal to or greater than 0.75.\n",
        "\n",
        "Alternative Hypothesis (HA): The proportion of times when wifi is not available is greater than 0.25, or the proportion of times when wifi is available is less than 0.75."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Defining the null hypothesis proportion\n",
        "null_prop = 0.75\n",
        "\n",
        "# Defining the sample size\n",
        "n = 50\n",
        "\n",
        "# Calculating the probability of observing k devices with wifi availability\n",
        "k = range(0, n+1)\n",
        "null_probabilities = [stats.binom.pmf(x, n, null_prop) for x in k]\n",
        "\n",
        "# Printing the probability of observing exactly k devices with wifi availability\n",
        "for k_val, probability in zip(k, null_probabilities):\n",
        "    print(f\"k = {k_val}, probability = {probability}\")"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The proportion of devices with wifi availability is equal to 0.75.\n",
        "# The proportion of devices with wifi availability is not equal to 0.75.\n",
        "# Setting the significance level\n",
        "alpha = 0.05\n",
        "\n",
        "# Defining the sample size and number of devices with wifi availability\n",
        "n = 100\n",
        "num_with_wifi = 75\n",
        "\n",
        "# Performing the test\n",
        "test_result = smprop.proportions_ztest(num_with_wifi, n, value=0.75)\n",
        "\n",
        "# Extracting the test statistic and p-value\n",
        "test_stat, p_value = test_result\n",
        "\n",
        "# Printing the results\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis.\")\n",
        "\n",
        "print(\"Test statistic:\", test_stat)\n",
        "print(\"p-value:\", p_value)"
      ],
      "metadata": {
        "id": "n3VxGQ6DKmsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We used the one-sample proportion test to compare the sample's wifi availability proportion (25%) to the known population proportion (0.75). The resulting p-value indicates the likelihood of observing the sample proportion assuming the population proportion is 0.75. A p-value < 0.05 leads us to reject the null, indicating a significant difference, while  0.05 suggests no strong evidence for a significant distinction."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The one-sample proportion test was chosen due to its direct relevance to the research question on wifi availability proportion. With a known population proportion of 0.75 and a sample proportion of 0.25, this test is tailored for comparing proportions and evaluating statistical significance. By employing this test, we assessed the distinction between these proportions and made informed decisions on the null hypothesis. It was an apt choice to address the research inquiry based on available data."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3\n",
        "The proportion of 3G sim devices is approximately same across all price range."
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null hypothesis (H0): The proportion of devices with 3G sim is the same across all price ranges.\n",
        "\n",
        "Alternative hypothesis (HA): The proportion of devices with 3G sim is different across at least one pair of price ranges."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Constructing the contingency table\n",
        "contingency_table = pd.crosstab(df['price_range'], df['three_g'])\n",
        "\n",
        "# Performing the chi-square test of independence\n",
        "chi2, p_value, dof, expected = stats.chi2_contingency(contingency_table)\n",
        "\n",
        "# Printing the contingency table, chi-square statistic, and p-value\n",
        "print(\"Contingency Table:\\n\", contingency_table)\n",
        "print(\"Chi-square statistic:\", chi2)\n",
        "print(\"p-value:\", p_value)"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I employed the chi-square test of independence to analyze the connection between price range and the presence of three G sims in devices. This test assesses the significance of association between categorical variables. By calculating the chi-square statistic and p-value, it evaluates the observed vs. expected frequencies under the null hypothesis of no association. A small p-value (<0.05) leads to rejecting the null, signifying significant association, while a large p-value (0.05) implies no significant link between variables. This approach helped assess the relationship and informed decisions on variable association."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chi-square test examines observed and expected frequencies in a contingency table. If the chi-square statistic is large and p-value < 0.05, we reject the null hypothesis, implying significant association.\n",
        "\n",
        "In this case, the p-value obtained (0.7117) is above 0.05. Thus, we retain the null hypothesis, signifying no strong evidence for a significant link between price_range and three_g variables."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "mp_df.isnull().sum()"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here I use isnull() method to check missing values,No missing values available."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "plt.figure(figsize=(15,15))\n",
        "\n",
        "# Define a color palette\n",
        "color_palette = sns.color_palette(\"pastel\")\n",
        "\n",
        "# Loop through each column in the DataFrame's describe() method\n",
        "for index, item in enumerate([i for i in mp_df.describe().columns.to_list()]):\n",
        "\n",
        "    # Creating a subplot in a 5x5 grid, starting with the first subplot (index 0)\n",
        "    plt.subplot(5, 5, index + 1)\n",
        "\n",
        "    # Creating a box plot of the current column's data with custom palette\n",
        "    sns.boxplot(mp_df[item], palette=color_palette)\n",
        "\n",
        "    # Add the column name to the subplot title\n",
        "    plt.title(item)\n",
        "\n",
        "    # Add some spacing between the subplots\n",
        "    plt.subplots_adjust(hspace=0.5)\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "# Display the plots\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since there aren't many outliers present, there is no need to perform extensive experimentation."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Categorical encoding is not required as all the values are already in either integer or float format."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Textual Data Preprocessing is not required."
      ],
      "metadata": {
        "id": "s0PPM-0zM9QS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data\n",
        "# Select your features wisely to avoid overfitting\n",
        "\n",
        "# Defining X and y\n",
        "mp_df.drop(['px_height', 'px_width'], axis = 1, inplace = True)\n",
        "\n",
        "X = mp_df.drop(['price_range'], axis = 1)\n",
        "y = mp_df['price_range']\n"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have decided to remove the variables px_height and px_width from my data because they have minimal impact on the dependent variable, which is the price range."
      ],
      "metadata": {
        "id": "NPg07bFGPN0b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here I employ MinMaxScaler from Scikit-learn to scale variable X. This technique transforms data to a specified range (usually 0 to 1) by subtracting the minimum value and dividing by the range (max-min). MinMaxScaler suits cases with unknown or non-normal data distributions and handles outliers better than other scaling methods."
      ],
      "metadata": {
        "id": "SuShQZmkPjTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no need to do dimensionality reduction."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "# Defining X and y\n",
        "X = mp_df.drop(['price_range'], axis = 1)\n",
        "y = mp_df['price_range']"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding the shape of X and y\n",
        "print(f'shape of x is - {X.shape}')\n",
        "print(f'shape of y is - {y.shape}')"
      ],
      "metadata": {
        "id": "LsoyDaiaQ6DV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting dataset into train and test sets\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.20, random_state = 42)"
      ],
      "metadata": {
        "id": "eSOJM3ffRete"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding X_train and y_train shape\n",
        "print(f'shape of X_train is - {X_train.shape}')\n",
        "print(f'shape of y_train is - {y_train.shape}')"
      ],
      "metadata": {
        "id": "z1dYaJniRqBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The choice of data splitting ratio depends on various factors, including the size of the dataset, the availability of labeled data, the complexity of the problem, and the specific requirements of the task.\n",
        "\n",
        "However, in general, common data splitting ratios are often used in machine learning projects. One common practice is to use an 80-20 or 70-30 split for the training and testing sets. That means allocating 70% or 80% of the data for training the model and reserving the remaining 30% or 20% for testing and evaluation."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1  | Logistic Regression"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "log_reg = LogisticRegression()\n",
        "# Fit the Algorithm\n",
        "log_reg.fit(X_train, y_train)\n",
        "# Predict on the model\n",
        "y_pred_test = log_reg.predict(X_test)\n",
        "y_pred_train = log_reg.predict(X_train)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print('Classification report for Logistic Regression (Test set)= ')\n",
        "print(classification_report(y_pred_test, y_test))\n",
        "\n",
        "\n",
        "# Prediction on the model\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Generating the confusion matrix\n",
        "cf_matrix = confusion_matrix(y_test, y_pred_test)\n",
        "\n",
        "print(cf_matrix)\n",
        "\n",
        "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
        "\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "# Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels([0,1,2,3])\n",
        "ax.yaxis.set_ticklabels([0,1,2,3])\n",
        "\n",
        "# Displaying the visualization of the Confusion Matrix\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrics for train\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print('Classification report for Logistic Regression (Train set)= ')\n",
        "print( classification_report(y_pred_train, y_train))"
      ],
      "metadata": {
        "id": "-2jpOY1IU9uH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Logistic Regression model's classification report includes precision, recall, and F1-score for each class, along with support (instances count). Precision is the ratio of accurate positive predictions to total positive predictions, while recall is the ratio of accurate positive predictions to actual positives. F1-score balances precision and recall. The model achieved 83% accuracy on the training set, with similar scores for each class. The macro and weighted averages are both 83%. This indicates a reasonable model performance, yet further assessment on overfitting, underfitting, and test set performance is essential."
      ],
      "metadata": {
        "id": "6II9nMcGVPnu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "log_reg = LogisticRegression()\n",
        "scores = cross_val_score(log_reg, X_scaled, y, cv=5)\n",
        "\n",
        "print(\"Cross-validation scores:\", scores)\n",
        "print(\"Average cross-validation score:\", np.mean(scores))\n",
        "\n",
        "\n",
        "log_reg = LogisticRegression()\n",
        "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
        "grid = GridSearchCV(log_reg, param_grid, cv=5)\n",
        "# Fit the Algorithm\n",
        "grid.fit(X_scaled, y)\n",
        "# Predict on the model\n",
        "print(\"Best cross-validation score:\", grid.best_score_)\n",
        "print(\"Best parameters:\", grid.best_params_)\n",
        "print(\"Test set score:\", grid.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearchCV is a method for hyperparameter optimization in machine learning. It systematically explores a predefined hyperparameter grid to find the best combination for optimal model performance. It was chosen here to optimize the C hyperparameter in the logistic regression model, ensuring enhanced results on the validation set."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The logistic regression model demonstrated strong performance with a cross-validation score of 0.82. The optimal C value of 10 resulted in a consistent test set score of 0.82, suggesting minimal overfitting. This indicates the model's suitability for the dataset. Additional evaluation of precision, recall, and F1-score would provide a comprehensive view of its performance."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2 | Random Forest"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 2 Implementation\n",
        "rfc=RandomForestClassifier(n_estimators=200)\n",
        "# Fit the Algorithm\n",
        "rfc.fit(X_train, y_train)\n",
        "# Making the Prediction\n",
        "y_pred = rfc.predict(X_test)\n",
        "test_score= accuracy_score(y_test, y_pred)\n",
        "test_score\n",
        "y_pred_train = rfc.predict(X_train)\n",
        "train_score = accuracy_score(y_train, y_pred_train)\n",
        "train_score\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "5JicivCUaVV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating the confusion matrix\n",
        "cf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(cf_matrix)\n",
        "\n",
        "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
        "\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "# Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels([0,1,2,3])\n",
        "ax.yaxis.set_ticklabels([0,1,2,3])\n",
        "\n",
        "# Displaying the visualization of the Confusion Matrix\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6tlAA-PJbgPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importance = pd.DataFrame({'Feature':X.columns,\n",
        "                                   'Score':rfc.feature_importances_}).sort_values(by='Score', ascending=False).reset_index(drop=True)\n",
        "feature_importance.head()"
      ],
      "metadata": {
        "id": "G9MeWfYWdMWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(15,8))\n",
        "ax = sns.barplot(x=feature_importance['Score'], y=feature_importance['Feature'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Nu0NXddodfgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Random Forest classification model achieved an accuracy of 0.80. Its precision, recall, and F1-score ranged from 0.68 to 0.92 for different classes, indicating moderate overall performance in correctly predicting class labels."
      ],
      "metadata": {
        "id": "UoNlisMictQ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "params = {'n_estimators':[10,50],\n",
        "          'max_depth':[10,20],\n",
        "           'min_samples_split':[2,4],\n",
        "          'max_features':['sqrt','log2'],\n",
        "          'max_leaf_nodes':[10, 20]\n",
        "          }\n",
        "rf = RandomForestClassifier()\n",
        "clsr = GridSearchCV(rf, params, scoring='accuracy', cv=3)\n",
        "# Fit the Algorithm\n",
        "clsr.fit(X, y)\n",
        "# Predict on the model\n",
        "print(f'best_params_ : {clsr.best_params_}')\n",
        "print(f'best_estimator_ : {clsr.best_estimator_}')\n",
        "print(f'best_score_ : {clsr.best_score_}')"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "clsr = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
        "                       criterion='gini', max_depth=30, max_features='log2',\n",
        "                       max_leaf_nodes=40, max_samples=None,\n",
        "                       min_impurity_decrease=0.0,\n",
        "                       min_samples_leaf=1, min_samples_split=4,\n",
        "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
        "                       n_jobs=None, oob_score=False, random_state=None,\n",
        "                       verbose=0, warm_start=False)\n",
        "clsr.fit(X_train, y_train)\n",
        "# making prediction\n",
        "y_pred = clsr.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "oAxygGJvkETI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "nJr-ZI_4lsA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating the confusion matrix\n",
        "cf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(cf_matrix)\n",
        "\n",
        "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
        "\n",
        "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted Values')\n",
        "ax.set_ylabel('Actual Values ');\n",
        "\n",
        "# Ticket labels - List must be in alphabetical order\n",
        "ax.xaxis.set_ticklabels([0,1,2,3])\n",
        "ax.yaxis.set_ticklabels([0,1,2,3])\n",
        "\n",
        "# Displaying the visualization of the Confusion Matrix.\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rzSUnHuKl0TQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clsr.predict(X_train)\n",
        "accuracy_score(y_train, y_pred)"
      ],
      "metadata": {
        "id": "-5w2PHbTl6s1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_train, y_pred))"
      ],
      "metadata": {
        "id": "IpuxgLMTl_Jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importance = pd.DataFrame({'Feature':X.columns,\n",
        "                                   'Score':clsr.feature_importances_}).sort_values(by='Score', ascending=False).reset_index(drop=True)\n",
        "feature_importance.head()"
      ],
      "metadata": {
        "id": "BU58w_8mmDGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used GridSearchCV, a powerful hyperparameter optimization technique. This approach systematically explores hyperparameter values for an estimator, leveraging cross-validation to evaluate each combination. By automating parameter tuning, GridSearchCV identifies the best hyperparameters, enhancing model performance."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model's performance has improved slightly, with accuracy increasing from 0.80 to 0.81 and weighted average F1-score improving from 0.80 to 0.81. While precision and recall scores have generally increased, the macro average scores remain unchanged. Overall, there's a modest enhancement in the model's performance."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The evaluation metrics include class-specific precision, recall, and F1-score, along with the weighted average and macro average. The weighted average considers class imbalance, providing an overall assessment of model performance. The macro average assesses each class individually. The confusion matrix identifies misclassifications for a deeper understanding. These metrics collectively offer valuable insights into the model's impact on business performance."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3 | Decision Trees"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "dtc=DecisionTreeClassifier(max_depth=5)\n",
        "# Fit the Algorithm\n",
        "dtc.fit(X_train,y_train)\n",
        "# Predict on the model\n",
        "y_pred3_test=dtc.predict(X_test)"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score =accuracy_score(y_test,y_pred3_test)\n",
        "print(f'score : {score}')\n",
        "print(\"classifcation report for decision tree classifier\")\n",
        "print(classification_report(y_pred3_test,y_test))"
      ],
      "metadata": {
        "id": "SFMR4XGfoD9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "DTgrid = GridSearchCV(dtc, param_grid = {'max_depth': (5, 30), 'max_leaf_nodes': (10, 100)}, scoring = 'accuracy', cv = 5, verbose = 24)\n",
        "# Fit the Algorithm\n",
        "DTgrid.fit(X_train,y_train)\n",
        "# Predict on the model\n",
        "y_pred3test=DTgrid.predict(X_test)"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Classification Report for Decision Tree (test set)= ')\n",
        "print(classification_report(y_test, y_pred3_test))"
      ],
      "metadata": {
        "id": "Ht0gJZ4BqFYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "cf_matrix=confusion_matrix(y_test,y_pred3_test)\n",
        "vis=sns.heatmap(cf_matrix, annot=True , cmap='coolwarm')"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The hyperparameter optimization technique used is GridSearchCV. It systematically explores the specified parameter grid to find the best combination of hyperparameters for the Decision Tree classifier. GridSearchCV is chosen for its exhaustive search approach, ensuring comprehensive exploration of hyperparameter space to enhance model performance."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, there is an improvement in the model's performance. The heatmap of the confusion matrix visually indicates the changes in prediction results. Update the Evaluation Metric Score Chart to reflect the improved scores and their corresponding metrics."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I opted for Random Forest and logistic regression models as they outperformed the random forest regression in terms of prediction accuracy and results."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest:\n",
        "\n",
        "And reason why i have choosen Random Forest is because it is an ensemble model that combines multiple decision trees. It handles non-linear relationships, works well with high-dimensional data, and is robust against overfitting. It can capture complex interactions between features and provide estimates of feature importance."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic regression** is a linear classification algorithm that estimates the probability of a binary outcome, such as mobile phone price range, based on input features. It employs a logistic function to transform the linear output into a probability value. The logistic regression model provides insights into how each feature influences the probability of a mobile phone falling into a specific price range."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "EDA Insights :\n",
        "\n",
        "1. For Bluethooth variable half the devices have Bluetooth, and half dont\n",
        "\n",
        "2. There is a gradual increase in battery as the price range increases\n",
        "\n",
        "3. Ram has continuous increase with price range while moving from Low cost to Very high cost\n",
        "\n",
        "3. Costleir phones are lighter\n",
        "\n",
        "4. RAM, battery power, pixels played more significant role in deciding the price range of mobile phone.\n",
        "\n",
        "Model Insights :\n",
        "\n",
        "For Mobile price range prediction we have used\n",
        "\n",
        "1.Logistic Regression\n",
        "\n",
        "2.Random Forest\n",
        "\n",
        "3.Decision Tree\n",
        "\n",
        "\n",
        "From the implemented models the best-performing model among the implemented models is Logistic Regression. Here are the reasons:\n",
        "\n",
        "Logistic Regression achieved the highest accuracy of 0.90, indicating that it correctly predicted the class labels for a significant portion of the test data.\n",
        "\n",
        "The precision, recall, and F1-score for each class in the Logistic Regression classification report are generally high, indicating a good balance between correctly identifying positive and negative instances for each class.\n",
        "\n",
        "While Random Forest also achieved good accuracy scores, the evaluation metrics, such as precision, recall, and F1-score, for Logistic Regression appear to be slightly better.\n",
        "\n",
        "1.Logistic Regression\n",
        "\n",
        "accuracy                                     0.90       500\n",
        "macro avg                0.90      0.90      0.90       500\n",
        "weighted avg             0.91      0.90      0.90       500\n",
        "\n",
        "\n",
        "2.Random Forest\n",
        "\n",
        "accuracy                                     0.89       500\n",
        "macro avg                0.89      0.89      0.89       500\n",
        "weighted avg             0.89      0.89      0.89       500\n",
        "\n",
        "\n",
        "** Random Forrest cross validation results **\n",
        "\n",
        "accuracy                                     0.86       600\n",
        "macro avg                0.86      0.86      0.86       600\n",
        "weighted avg             0.86      0.86      0.86       600\n",
        "\n",
        "\n",
        "3.Decision Tree\n",
        "\n",
        "accuracy                                     0.81       500\n",
        "macro avg                0.81      0.81      0.81       500\n",
        "weighted avg             0.81      0.81      0.81       500\n",
        "\n",
        "** Decision tree cross validation results **\n",
        "\n",
        "accuracy                                     0.81       500\n",
        "macro avg                0.81      0.81      0.81       500\n",
        "weighted avg             0.82      0.81      0.81       500"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}